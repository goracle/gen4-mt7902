From: Recovery Fix <fix@example.com>
Date: Mon, 2 Feb 2026 12:00:00 -0800
Subject: [PATCH] pcie: Fix "scheduling while atomic" by deferring recovery to workqueue

This patch fixes the kernel panic "BUG: scheduling while atomic" that occurs
when mt79xx_pci_function_recover() is called from IRQ/tasklet/atomic context.

The issue: mt79xx_pci_function_recover() contains many blocking operations
(msleep, mdelay, pci_reset_function, etc.) but can be called from atomic
context (ISR -> tasklet -> MMIO read -> 0xffffffff -> recovery).

The solution: 
1. Add workqueue infrastructure to defer recovery to process context
2. Add atomic context detection with in_atomic() check
3. Create fast MMIO liveness check for use in IRQ/tasklet paths
4. Schedule recovery work when MMIO failure detected in atomic context
5. Add proper locking and state management

Changes:
- Add state_flags, recovery_work, recovery_lock to GL_HIF_INFO
- Implement mt7902_mmio_dead() for fast MMIO checking
- Implement mt7902_schedule_recovery_from_atomic() to schedule work
- Implement mt7902_recovery_work() as workqueue handler
- Modify mt79xx_pci_function_recover() to check context before sleeping
- Add MMIO checks in interrupt handler
- Initialize new fields in glBusSetIrq()

Signed-off-by: Recovery Fix <fix@example.com>
---
 os/linux/hif/pcie/include/hif.h | 10 ++++
 os/linux/hif/pcie/pcie.c        | 120 +++++++++++++++++++++++++++++++++++-
 2 files changed, 128 insertions(+), 2 deletions(-)

diff --git a/os/linux/hif/pcie/include/hif.h b/os/linux/hif/pcie/include/hif.h
index 1234567..abcdefg 100644
--- a/os/linux/hif/pcie/include/hif.h
+++ b/os/linux/hif/pcie/include/hif.h
@@ -1,5 +1,8 @@
 /* Assuming this is where GL_HIF_INFO is defined */
 
+/* State flags for atomic-safe recovery management */
+#define MTK_FLAG_MMIO_GONE     0  /* bit 0: MMIO dead, needs recovery */
+
 struct GL_HIF_INFO {
 	/* ... existing fields ... */
 	
@@ -12,6 +15,13 @@ struct GL_HIF_INFO {
 	uint8_t u8RecoveryFailReason;
 	unsigned long u_recovery_fail_time;
 	
+	/* NEW: Recovery infrastructure for atomic context safety */
+	unsigned long state_flags;          /* Atomic state flags (MTK_FLAG_*) */
+	struct work_struct recovery_work;   /* Workqueue for deferred recovery */
+	struct mutex recovery_lock;         /* Protects recovery sequence */
+	int saved_irq;                      /* Saved IRQ number for disable/enable */
+	struct pci_dev *pdev;               /* PCI device pointer */
+	
 	/* ... rest of existing fields ... */
 };
 
diff --git a/os/linux/hif/pcie/pcie.c b/os/linux/hif/pcie/pcie.c
index 1234567..abcdefg 100644
--- a/os/linux/hif/pcie/pcie.c
+++ b/os/linux/hif/pcie/pcie.c
@@ -74,6 +74,7 @@
 #include "gl_os.h"
 
 #include "hif_pdma.h"
+#include <linux/workqueue.h>
 #include <linux/pm_runtime.h>
 
 #include "precomp.h"
@@ -265,6 +266,109 @@ void pcieRegisterIrq(struct GLUE_INFO *prGlueInfo)
 }
 
 /*----------------------------------------------------------------------------*/
+/*! \brief Fast MMIO liveness check - safe in atomic context
+ *
+ * Performs a lightweight read of a known-safe register to detect if the
+ * MMIO region has become inaccessible (returns 0xffffffff).
+ *
+ * This uses a chip ID or version register that should always return a
+ * valid value. Adjust the offset based on your chip.
+ *
+ * \param[in] prHifInfo Pointer to HIF info structure
+ *
+ * \return TRUE if MMIO is dead (0xffffffff), FALSE if alive
+ */
+/*----------------------------------------------------------------------------*/
+static inline u_int8_t mt7902_mmio_dead(struct GL_HIF_INFO *prHifInfo)
+{
+	uint32_t u4Val;
+	
+	if (!prHifInfo || !prHifInfo->CSRBaseAddress)
+		return TRUE;
+	
+	/* Read a safe register - using chip ID register at offset 0x0
+	 * Adjust this offset if needed for your specific chip */
+	u4Val = readl(prHifInfo->CSRBaseAddress + 0x0);
+	
+	return (u4Val == 0xFFFFFFFF);
+}
+
+/*----------------------------------------------------------------------------*/
+/*! \brief Schedule recovery from atomic/IRQ/tasklet context
+ *
+ * This function is safe to call from IRQ handlers, tasklets, and other
+ * atomic contexts. It sets a flag, disables interrupts, and schedules
+ * a workqueue to perform the actual recovery (which can sleep).
+ *
+ * \param[in] prGlueInfo Pointer to glue info structure
+ */
+/*----------------------------------------------------------------------------*/
+static void mt7902_schedule_recovery_from_atomic(struct GLUE_INFO *prGlueInfo)
+{
+	struct GL_HIF_INFO *prHifInfo;
+	
+	if (!prGlueInfo)
+		return;
+		
+	prHifInfo = &prGlueInfo->rHifInfo;
+	
+	/* If already scheduled, do nothing (test_and_set_bit is atomic) */
+	if (test_and_set_bit(MTK_FLAG_MMIO_GONE, &prHifInfo->state_flags)) {
+		DBGLOG(HAL, WARN, "Recovery already scheduled, skipping\n");
+		return;
+	}
+	
+	DBGLOG(HAL, WARN, "MMIO failure detected in atomic context - scheduling recovery\n");
+	
+	/* Disable further interrupts to prevent re-entry (nosync is atomic-safe) */
+	if (prHifInfo->saved_irq > 0)
+		disable_irq_nosync(prHifInfo->saved_irq);
+	
+	/* Stop network queues without sleeping */
+	if (prGlueInfo->prDevHandler)
+		netif_tx_stop_all_queues(prGlueInfo->prDevHandler);
+	
+	/* Schedule the actual recovery work (will run in process context) */
+	schedule_work(&prHifInfo->recovery_work);
+}
+
+/*----------------------------------------------------------------------------*/
+/*! \brief Recovery workqueue handler - runs in process context
+ *
+ * This function runs in process context and is allowed to sleep.
+ * It calls the full recovery procedure which contains msleep, mdelay,
+ * pci_reset_function, and other blocking operations.
+ *
+ * \param[in] work Pointer to work_struct (embedded in GL_HIF_INFO)
+ */
+/*----------------------------------------------------------------------------*/
+static void mt7902_recovery_work(struct work_struct *work)
+{
+	struct GL_HIF_INFO *prHifInfo;
+	struct GLUE_INFO *prGlueInfo;
+	uint32_t u4Status;
+	
+	prHifInfo = container_of(work, struct GL_HIF_INFO, recovery_work);
+	prGlueInfo = container_of(prHifInfo, struct GLUE_INFO, rHifInfo);
+	
+	/* Ensure only one recovery runs at a time */
+	if (!mutex_trylock(&prHifInfo->recovery_lock)) {
+		DBGLOG(HAL, WARN, "Recovery already in progress, skipping\n");
+		return;
+	}
+	
+	DBGLOG(HAL, WARN, "=== Recovery work starting (process context) ===\n");
+	
+	/* Call the actual recovery function - it's now safe to sleep */
+	u4Status = mt79xx_pci_function_recover(prHifInfo->pdev, prGlueInfo);
+	
+	if (u4Status == WLAN_STATUS_SUCCESS) {
+		DBGLOG(HAL, WARN, "=== Recovery work completed successfully ===\n");
+		clear_bit(MTK_FLAG_MMIO_GONE, &prHifInfo->state_flags);
+	} else {
+		DBGLOG(HAL, ERROR, "=== Recovery work FAILED ===\n");
+	}
+	
+	mutex_unlock(&prHifInfo->recovery_lock);
+}
+
+/*----------------------------------------------------------------------------*/
 /*!
  * \brief This function is a PCIE interrupt callback function
  *
@@ -275,11 +379,22 @@ void pcieRegisterIrq(struct GLUE_INFO *prGlueInfo)
 static irqreturn_t mtk_pci_interrupt(int irq, void *dev_instance)
 {
 	struct GLUE_INFO *prGlueInfo = NULL;
+	struct GL_HIF_INFO *prHifInfo = NULL;
 
 	prGlueInfo = (struct GLUE_INFO *) dev_instance;
 	if (!prGlueInfo) {
 		DBGLOG(HAL, INFO, "No glue info in mtk_pci_interrupt()\n");
 		return IRQ_NONE;
+	}
+	
+	prHifInfo = &prGlueInfo->rHifInfo;
+	
+	/* CRITICAL: Check MMIO liveness before accessing hardware */
+	if (mt7902_mmio_dead(prHifInfo)) {
+		DBGLOG(HAL, ERROR, "MMIO dead in ISR - scheduling recovery\n");
+		mt7902_schedule_recovery_from_atomic(prGlueInfo);
+		return IRQ_HANDLED;
+	}
 
 	halDisableInterrupt(prGlueInfo->prAdapter);
 
@@ -1002,11 +1117,22 @@ void dump_pdma_state(struct ADAPTER *prAdapter)
 uint32_t mt79xx_pci_function_recover(struct pci_dev *pdev,
 					    struct GLUE_INFO *prGlueInfo)
 {
 	struct ADAPTER *prAdapter;
 	struct mt66xx_chip_info *prChipInfo;
 	struct REG_INFO *prRegInfo;
 	uint32_t u4Status;
 	struct GL_HIF_INFO *prHifInfo;
 	uint32_t u4Val;
 	int pm_ret;
+	
+	/* CRITICAL: Detect if we're in atomic context */
+	if (in_atomic() || in_interrupt() || irqs_disabled()) {
+		DBGLOG(HAL, ERROR, 
+			"mt79xx_pci_function_recover called in atomic context! "
+			"Scheduling workqueue instead.\n");
+		mt7902_schedule_recovery_from_atomic(prGlueInfo);
+		return WLAN_STATUS_PENDING;
+	}
+	
+	DBGLOG(HAL, INFO, "Recovery running in process context - safe to sleep\n");
 
 	/* Tier-4: SAFETY FIRST - Silence the Bus Immediately */
 	/* This prevents the "Hold Power Button" hard lock */
@@ -1433,6 +1559,16 @@ u_int8_t glBusSetIrq(struct net_device *prNetDevice,
 	ASSERT(prGlueInfo);
 	prHifInfo = &prGlueInfo->rHifInfo;
 
+	/* Initialize recovery infrastructure */
+	INIT_WORK(&prHifInfo->recovery_work, mt7902_recovery_work);
+	mutex_init(&prHifInfo->recovery_lock);
+	prHifInfo->state_flags = 0;
+	prHifInfo->saved_irq = pdev->irq;
+	prHifInfo->pdev = pdev;
+	
+	DBGLOG(HAL, INFO, "Recovery infrastructure initialized (IRQ=%d)\n", 
+		prHifInfo->saved_irq);
+
 	prHifInfo->u4IrqId = pdev->irq;
 	ret = request_irq(prHifInfo->u4IrqId, mtk_pci_interrupt,
 		IRQF_SHARED, prNetDevice->name, prGlueInfo);
@@ -1483,6 +1619,11 @@ void glBusFreeIrq(struct net_device *prNetDevice,
 
 	synchronize_irq(pdev->irq);
 	free_irq(pdev->irq, prGlueInfo);
+	
+	/* Clean up recovery infrastructure */
+	cancel_work_sync(&prHifInfo->recovery_work);
+	mutex_destroy(&prHifInfo->recovery_lock);
+	DBGLOG(HAL, INFO, "Recovery infrastructure cleaned up\n");
 }
 
 /*----------------------------------------------------------------------------*/
-- 
2.34.1
